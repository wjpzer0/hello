# 题目

编写一个函数，输入是一个无符号整数（以二进制串的形式），返回其二进制表达式中数字位数为 '1' 的个数（也被称为汉明重量）。

提示：

请注意，在某些语言（如 Java）中，没有无符号整数类型。在这种情况下，输入和输出都将被指定为有符号整数类型，并且不应影响您的实现，因为无论整数是有符号的还是无符号的，其内部的二进制表示形式都是相同的。
在 Java 中，编译器使用二进制补码记法来表示有符号整数。因此，在上面的 示例 3 中，输入表示有符号整数 -3。


进阶：

如果多次调用这个函数，你将如何优化你的算法？


示例 1：

```
输入：00000000000000000000000000001011
输出：3
解释：输入的二进制串 00000000000000000000000000001011 中，共有三位为 '1'。
```


示例 2：

```
输入：00000000000000000000000010000000
输出：1
解释：输入的二进制串 00000000000000000000000010000000 中，共有一位为 '1'。
```


示例 3：

```
输入：11111111111111111111111111111101
输出：31
解释：输入的二进制串 11111111111111111111111111111101 中，共有 31 位为 '1'。
```


提示：

输入必须是长度为 32 的 二进制串 。

## 我的解法

```python
class Solution:
    def hammingWeight(self, n: int) -> int:
        strN = bin(n).replace('0b','')
        num = 0
        for i in strN:
            if i == '1':
                num += 1
            else:
                continue
        return num
```

仍然将数字转换字符串进行计数

## 其他解法

### 循环和位移动

```java
public int hammingWeight(int n) {
    int bits = 0;
    int mask = 1;
    for (int i = 0; i < 32; i++) {
        if ((n & mask) != 0) {
            bits++;
        }
        mask <<= 1;
    }
    return bits;
}
```

#### **算法**

这个方法比较直接。我们遍历数字的 32 位。如果某一位是 1 ，将计数器加一。

我们使用 位掩码 来检查数字的第 i^th位。一开始，掩码 m=1 因为 1 的二进制表示是
0000 0000 0000 0000 0000 0000 0000 0001

显然，任何数字跟掩码 1 进行逻辑与运算，都可以让我们获得这个数字的最低位。检查下一位时，我们将掩码左移一位。
0000 0000 0000 0000 0000 0000 0000 0010

并重复此过程。
复杂度分析

- 时间复杂度：O(1)。运行时间依赖于数字 nn 的位数。由于这题中 nn 是一个 32 位数，所以运行时间是 O(1) 的。

- 空间复杂度：O(1)。没有使用额外空间。


###### 位操作的小技巧

```java

public int hammingWeight(int n) {
    int sum = 0;
    while (n != 0) {
        sum++;
        n &= (n - 1);
    }
    return sum;
}
```

#### **算法**

我们可以把前面的算法进行优化。我们不再检查数字的每一个位，而是不断把数字最后一个 1 反转，并把答案加一。当数字变成 0 的时候偶，我们就知道它没有 1 的位了，此时返回答案。

这里关键的想法是对于任意数字 n ，将 n 和 n−1 做与运算，会把最后一个 1 的位变成 0 。为什么？考虑 n 和 n−1 的二进制表示。

![image.png](https://pic.leetcode-cn.com/abfd6109e7482d70d20cb8fc1d632f90eacf1b5e89dfecb2e523da1bcb562f66-image.png)

图片 1. 将 n 和 n-1做与运算会将最低位的 1 变成 0

在二进制表示中，数字 n 中最低位的 1 总是对应 n−1 中的 0 。因此，将 n 和 n - 1 与运算总是能把 n 中最低位的 1 变成 0，并保持其他位不变。

使用这个小技巧，代码变得非常简单。

复杂度分析

- 时间复杂度：O(1) 。运行时间与 n中位为 1 的有关。在最坏情况下， n 中所有位都是 1 。对于 32 位整数，运行时间是 O(1) 的。

- 空间复杂度：O(1) 。没有使用额外空间。

### 调用函数懒蛋法

```Python
class Solution(object):
    def hammingWeight(self, n):
        """
        :type n: int
        :rtype: int
        """
        return bin(n).count('1')
```

### 手动循环计算 1 的个数

```Python
class Solution(object):
    def hammingWeight(self, n):
        """
        :type n: int
        :rtype: int
        """
        n = bin(n)
        count = 0
        for c in n:
            if c == "1":
                count += 1
        return count  
```

### 对 2 取余

十进制转二进制的方式。每次对 2 取余判断是否是 1，是的话就 count = count + 1。

```Python
class Solution(object):
    def hammingWeight(self, n):
        """
        :type n: int
        :rtype: int
        """
        count = 0
        while n:
            res = n % 2
            if res == 1:
                count += 1
            n //= 2
        return count
```



### 位运算法

把 n 与 1 进行与运算，将得到 n 的最低位数字。因此可以取出最低位数，再将 n 右移一位。循环此步骤，直到 n 等于零。

```Python
class Solution(object):
    def hammingWeight(self, n):
        """
        :type n: int
        :rtype: int
        """
        count = 0
        while n:
            count += n&1
            n >>= 1
        return count
```

## 「分组统计」解法

```python
class Solution:
    def hammingWeight(self, n: int) -> int:
        n = (n & 0x55555555) + ((n >> 1)  & 0x55555555);
        n = (n & 0x33333333) + ((n >> 2)  & 0x33333333);
        n = (n & 0x0f0f0f0f) + ((n >> 4)  & 0x0f0f0f0f);
        n = (n & 0x00ff00ff) + ((n >> 8)  & 0x00ff00ff);
        n = (n & 0x0000ffff) + ((n >> 16) & 0x0000ffff);
        return n;
```

#### Integer.bitCount

```java
public static int bitCount(int i) {
    // HD, Figure 5-2
    i = i - ((i >>> 1) & 0x55555555);
    i = (i & 0x33333333) + ((i >>> 2) & 0x33333333);
    i = (i + (i >>> 4)) & 0x0f0f0f0f;
    i = i + (i >>> 8);
    i = i + (i >>> 16);
    return i & 0x3f;
}
```

最后,其实java的Integer类已经提供了一个方法来统计bit位（无符号右移，可以统计负数的），乍看之下，WTF?
原理：想象一下，当一列的1摆在我们人脑的面前，我们会怎么数？一个一个数，第一个的算法的原理。或者两个两个地数？本方法就是如此实现的。如下图：

```
             二进制                       十进制
 1  0   1  1   1  1   1  1   1  1     10 11 11 11 11
  01     10     10     10     10       1 2  2  2  2
          \     /       \     /           \/    \/
  01       0100           0100         1   4    4
                \       /                   \  /
  01               1000                1      8
      \          /                       \   /
          1001                             9
          
              767的二进制中的1的位数计算过程
```

每两位bit为一组，分别统计有几个1，然后把结果存到这两个bit位上，如：`11`有2个1，结果为`10`，`10`替代`11`的存储到原位置。然后进行加法计算，把所有的结果加起来。加的过程中呢又可以两两相加，减少计算流程。

两个bit计算1的数量：`0b11: 0b01 + 0b01 = 0b10 = 2`, `0b10: 0b01 + 0b00 = 0b01 = 1`，这样就清楚了。

算法实现如下：

- 首先整数i抹除左一位：`i & 0x55555555`，然后错位相加。`(i >>> 1) & 0x55555555`表示：左位移到右边，再把左位抹除，这样就可以计算两个bit位上1的个数了：`0b1011=>0b0001 + 0b0101 = 0b0110`左两位有1个1，右两位有2个1。
- 这时`i`中存储了每两位的统计结果，可以进行两两相加，最后求和。

过程：

```
0x55555555  ‭0b01010101010101010101010101010101‬
0x33333333  ‭0b00110011001100110011001100110011‬
0x0f0f0f0f  ‭0b00001111000011110000111100001111‬
0x00ff00ff  0b00000000111111110000000011111111
0x0000ffff  ‭0b00000000000000001111111111111111‬
0x3f        ‭0b00111111‬

0b11 11 11 11 11    (i & 0x55555555) + ((i >>> 1) & 0x55555555)  = 0b0101010101‬ + 0b0101010101 = 0b1010101010
0b10 10 10 10 10    (i & 0x33333333) + ((i >>> 2) & 0x33333333) = 0b1000100010 + 0b00100010 = 0b1001000100
0b10 01 00 01 00    (i & 0x0f0f0f0f) + ((i >>> 4) & 0x0f0f0f0f) = 0b1000000100 + 0b0100 = 0b1000001000
0b10 00 00 10 00    (i & 0x00ff00ff) + ((i >>> 8) & 0x00ff00ff) = 0b1000 + 0b10 = 0b1010
0b00 00 00 10 10    (i & 0x0000ffff) + ((i >>> 16) & 0x0000ffff) = 0b1010 + 0 = 0b1010
dec           10
```

算法原型：

```
public static int bitCount(int i) {
    i = (i & 0x55555555) + ((i >>> 1) & 0x55555555);
    i = (i & 0x33333333) + ((i >>> 2) & 0x33333333);
    i = (i & 0x0f0f0f0f) + ((i >>> 4) & 0x0f0f0f0f);
    i = (i & 0x00ff00ff) + ((i >>> 8) & 0x00ff00ff);
    i = (i & 0x0000ffff) + ((i >>> 16) & 0x0000ffff);
    return i;
}
```

时间复杂度O(1),可以，很ok了！但是写文章都要润色下的，别说算法了，然后优化过后的就是Integer中的实现了。
优化：

- 第一步：两个bit计算1的数量：`0b11: 0b01 + 0b01 = 0b10 = 2`, `0b10: 0b00 + 0b01 = 0b01 = 1`。研究发现：`2=0b11-0b1`，`1=0b10-0b1`,可以减少一次位于计算：`i = i - ((i >>> 1) & 0x55555555)`
- 第二步：暂时没有好的优化方法
- 第三步：实际是计算每个byte中的1的数量，最多8（0b1000）个，占4bit，可以最后进行位与运算消位，减少一次`&`运算：`i = (i + (i >>> 4)) & 0x0f0f0f0f`
- 第四,五步：同上理由，可以最后消位。但是由于int最多32（0b100000）个1，所以这两步可以不消位，最后一步把不需要的bit位抹除就可以了：`i & 0x3f`

感悟：大道至简，看似复杂的算法，其实现原理却是我们大脑的简单思维逻辑

```
7    0b111
i = 7 - ((7>>>1) & 0x55555555) = 6 = 0b110
i = (6 & 0x33333333) + ((6 >>> 2) & 0x33333333) = 2 + 1 = 3 = 0b11
i = (3 + (i >>> 4)) & 0x0f0f0f0f = 3 & 0x0f0f0f0f = 3 = 0b11
i = 3 + (3 >>> 8) = 3 = 0b11
i = 3 + (3 >>> 16) = 3 = 0b11
i = 3 & 0x3f = 3
```

